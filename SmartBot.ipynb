{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirthavarshini05/Rap_Rag/blob/main/SmartBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8ODikiR2sUA",
        "outputId": "24a5119f-30b2-4f5e-c532-264396cb2e47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.7)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m451.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, bs4, streamlit\n",
            "Successfully installed bs4-0.0.2 pydeck-0.9.1 pyngrok-7.3.0 streamlit-1.47.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit transformers bs4 requests pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 30rgZqrKIqeE2M62bA6Z1Yk8p2d_4uiuN89n9ft7x2ohawyZQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_7umRuu3UGP",
        "outputId": "a72e936b-9b54-4d17-cb83-434ed04b8839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import re\n",
        "import concurrent.futures\n",
        "import time\n",
        "from difflib import SequenceMatcher\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmo0TCCq2zCQ",
        "outputId": "f8c84cea-85b1-4efd-b2f7-47ebd3a94846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a app.py\n",
        "def is_relevant(name, text):\n",
        "    ratio = SequenceMatcher(None, name.lower(), text.lower()).ratio()\n",
        "    return name.lower() in text.lower() or ratio > 0.6\n",
        "\n",
        "def fetch_article(item, headers):\n",
        "    try:\n",
        "        resp = requests.get(item['link'], headers=headers, timeout=5)\n",
        "        resp.raise_for_status()\n",
        "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "        text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "        if len(text) < 200:\n",
        "            text = item['snippet']\n",
        "        return {'title': item['title'], 'text': text, 'source_link': item['link']} if len(text) > 50 else None\n",
        "    except:\n",
        "        return None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in-vhdta2zQh",
        "outputId": "4a8b3fc6-3538-4934-9d41-e6ffad3ff400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a app.py\n",
        "def search_and_scrape(company):\n",
        "    url = f\"https://www.bing.com/news/search?q={company.replace(' ', '+')}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    except:\n",
        "        return [], False\n",
        "\n",
        "    results = soup.find_all('a', class_='title')[:5]\n",
        "    snippets = soup.find_all('div', class_='snippet')\n",
        "\n",
        "    if not results:\n",
        "        return [], False\n",
        "\n",
        "    articles = []\n",
        "    relevant_count = 0\n",
        "\n",
        "    for i, link in enumerate(results):\n",
        "        title = link.get_text()\n",
        "        snippet = snippets[i].get_text() if i < len(snippets) else \"\"\n",
        "        if is_relevant(company, title) or is_relevant(company, snippet):\n",
        "            relevant_count += 1\n",
        "            articles.append({'title': title, 'link': link['href'], 'snippet': snippet})\n",
        "\n",
        "    if relevant_count < 2:\n",
        "        return [], False\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        fetched = executor.map(lambda a: fetch_article(a, headers), articles)\n",
        "        final_articles = [r for r in fetched if r]\n",
        "\n",
        "    return final_articles, True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmAKN-h72zT9",
        "outputId": "1f25626e-2305-4d7e-a183-6e1a812ccd33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a app.py\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "def summarize(articles, style):\n",
        "    summaries = []\n",
        "    for art in articles[:3]:\n",
        "        text = f\"summarize: {art['text'][:700]}\"\n",
        "        inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0,\n",
        "                             num_beams=4, early_stopping=True)\n",
        "        summary = tokenizer.decode(ids[0], skip_special_tokens=True)\n",
        "\n",
        "        if style == \"Quick bullet points\":\n",
        "            summary = \"- \" + summary.replace(\". \", \"\\n- \")\n",
        "        elif style == \"Casual conversation\":\n",
        "            summary = \"Here's what I found: \" + summary\n",
        "\n",
        "        summaries.append({\"title\": art['title'], \"summary\": summary, \"source_link\": art['source_link']})\n",
        "    return summaries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztOSbDAj3iEV",
        "outputId": "aa426dd5-568b-4d23-b544-0f9e66e26611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a app.py\n",
        "def extract_names(user_input):\n",
        "    keywords = [\"news\", \"about\", \"latest\", \"updates\", \"tell\", \"information\", \"info\", \"on\", \"for\"]\n",
        "    cleaned = re.sub(r'\\b(?:' + '|'.join(keywords) + r')\\b', '', user_input.lower())\n",
        "    cleaned = cleaned.replace(\" and \", \",\")\n",
        "    names = re.split(r'[,\\n]+', cleaned)\n",
        "    return [n.strip().capitalize() for n in names if n.strip()]\n",
        "\n",
        "def conversation_reply(user_input):\n",
        "    greetings = [\"hi\", \"hello\", \"how are you\", \"hey\"]\n",
        "    thanks = [\"thank you\", \"thanks\", \"thx\", \"thank u\"]\n",
        "    goodbyes = [\"bye\", \"goodbye\", \"see you\"]\n",
        "\n",
        "    text = user_input.lower()\n",
        "\n",
        "    if any(g in text for g in greetings):\n",
        "        return \"👋 Hi! I can fetch the latest news about any company. Type one or multiple names.\"\n",
        "    elif any(t in text for t in thanks):\n",
        "        return \"😊 You're welcome! Happy to help.\"\n",
        "    elif any(gb in text for gb in goodbyes):\n",
        "        return \"👋 Goodbye! Have a great day!\"\n",
        "    return None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNEeX7nk3lIr",
        "outputId": "9e560895-33c6-4b04-e274-4254d0b91857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a app.py\n",
        "def main():\n",
        "    st.title(\"📰 Smart Company News Chatbot\")\n",
        "\n",
        "    if 'chat_history' not in st.session_state:\n",
        "        st.session_state.chat_history = []\n",
        "\n",
        "    output_style = st.radio(\"Output style:\",\n",
        "                            ('Formal business summary', 'Quick bullet points', 'Casual conversation'))\n",
        "\n",
        "    for msg in st.session_state.chat_history:\n",
        "        with st.chat_message(\"user\" if msg[\"role\"] == \"user\" else \"assistant\"):\n",
        "            st.markdown(msg[\"text\"])\n",
        "\n",
        "    user_input = st.chat_input(\"Type your message...\")\n",
        "    if user_input:\n",
        "        start = time.time()\n",
        "        st.session_state.chat_history.append({\"role\": \"user\", \"text\": user_input})\n",
        "\n",
        "        reply = conversation_reply(user_input)\n",
        "        if reply:\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.markdown(reply)\n",
        "            st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": reply})\n",
        "        else:\n",
        "            names = extract_names(user_input)\n",
        "            if not names:\n",
        "                combined_response = \"⚠️ Invalid input. Please enter company names.\"\n",
        "            else:\n",
        "                combined_response = \"\"\n",
        "                with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "                    results = list(executor.map(search_and_scrape, names))\n",
        "\n",
        "                for name, (data, is_valid) in zip(names, results):\n",
        "                    if not is_valid or not data:\n",
        "                        combined_response += f\"\\n⚠️ Invalid company name: '{name}'.\\n\"\n",
        "                    else:\n",
        "                        summarized = summarize(data, output_style)\n",
        "                        combined_response += f\"\\n### 📰 News for {name}:\\n\"\n",
        "                        for item in summarized:\n",
        "                            combined_response += f\"- **{item['title']}**\\n  {item['summary']}\\n  [Source]({item['source_link']})\\n\\n\"\n",
        "\n",
        "                total_time = round(time.time() - start, 2)\n",
        "                combined_response += f\"\\n⏱️ Response time: {total_time}s\"\n",
        "\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.markdown(combined_response)\n",
        "            st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": combined_response})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UryJMTIj3n6r",
        "outputId": "da82a369-cc67-442a-95bd-cdff990b0b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import re\n",
        "import concurrent.futures\n",
        "import time\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# ---------------------------\n",
        "# Helper for relevance check\n",
        "# ---------------------------\n",
        "def is_relevant(name, text):\n",
        "    ratio = SequenceMatcher(None, name.lower(), text.lower()).ratio()\n",
        "    return name.lower() in text.lower() or ratio > 0.6\n",
        "\n",
        "# ---------------------------\n",
        "# Fetch article content\n",
        "# ---------------------------\n",
        "def fetch_article(item, headers):\n",
        "    try:\n",
        "        resp = requests.get(item['link'], headers=headers, timeout=5)\n",
        "        resp.raise_for_status()\n",
        "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "        text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "        if len(text) < 200:\n",
        "            text = item['snippet']\n",
        "        return {'title': item['title'], 'text': text, 'source_link': item['link']} if len(text) > 50 else None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# ---------------------------\n",
        "# Search and scrape with strict invalid detection\n",
        "# ---------------------------\n",
        "def search_and_scrape(company):\n",
        "    url = f\"https://www.bing.com/news/search?q={company.replace(' ', '+')}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    except:\n",
        "        return [], False\n",
        "\n",
        "    results = soup.find_all('a', class_='title')[:5]\n",
        "    snippets = soup.find_all('div', class_='snippet')\n",
        "\n",
        "    if not results:\n",
        "        return [], False\n",
        "\n",
        "    articles = []\n",
        "    relevant_count = 0\n",
        "\n",
        "    for i, link in enumerate(results):\n",
        "        title = link.get_text()\n",
        "        snippet = snippets[i].get_text() if i < len(snippets) else \"\"\n",
        "        if is_relevant(company, title) or is_relevant(company, snippet):\n",
        "            relevant_count += 1\n",
        "            articles.append({'title': title, 'link': link['href'], 'snippet': snippet})\n",
        "\n",
        "    # ✅ Strict invalid detection: Need at least 2 relevant matches\n",
        "    if relevant_count < 2:\n",
        "        return [], False\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        fetched = executor.map(lambda a: fetch_article(a, headers), articles)\n",
        "        final_articles = [r for r in fetched if r]\n",
        "\n",
        "    return final_articles, True\n",
        "\n",
        "# ---------------------------\n",
        "# Load summarizer\n",
        "# ---------------------------\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "    return tokenizer, model\n",
        "\n",
        "tokenizer, model = load_model()\n",
        "\n",
        "# ---------------------------\n",
        "# Summarize\n",
        "# ---------------------------\n",
        "def summarize(articles, style):\n",
        "    summaries = []\n",
        "    for art in articles[:3]:\n",
        "        text = f\"summarize: {art['text'][:700]}\"\n",
        "        inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "        ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0,\n",
        "                             num_beams=4, early_stopping=True)\n",
        "        summary = tokenizer.decode(ids[0], skip_special_tokens=True)\n",
        "\n",
        "        if style == \"Quick bullet points\":\n",
        "            summary = \"- \" + summary.replace(\". \", \"\\n- \")\n",
        "        elif style == \"Casual conversation\":\n",
        "            summary = \"Here's what I found: \" + summary\n",
        "\n",
        "        summaries.append({\"title\": art['title'], \"summary\": summary, \"source_link\": art['source_link']})\n",
        "    return summaries\n",
        "\n",
        "# ---------------------------\n",
        "# Extract company names\n",
        "# ---------------------------\n",
        "def extract_names(user_input):\n",
        "    keywords = [\"news\", \"about\", \"latest\", \"updates\", \"tell\", \"information\", \"info\", \"on\", \"for\"]\n",
        "    cleaned = re.sub(r'\\b(?:' + '|'.join(keywords) + r')\\b', '', user_input.lower())\n",
        "    cleaned = cleaned.replace(\" and \", \",\")\n",
        "    names = re.split(r'[,\\n]+', cleaned)\n",
        "    return [n.strip().capitalize() for n in names if n.strip()]\n",
        "\n",
        "# ---------------------------\n",
        "# Handle conversation\n",
        "# ---------------------------\n",
        "def conversation_reply(user_input):\n",
        "    greetings = [\"hi\", \"hello\", \"how are you\", \"hey\"]\n",
        "    thanks = [\"thank you\", \"thanks\", \"thx\", \"thank u\"]\n",
        "    goodbyes = [\"bye\", \"goodbye\", \"see you\"]\n",
        "\n",
        "    text = user_input.lower()\n",
        "\n",
        "    if any(g in text for g in greetings):\n",
        "        return \"👋 Hi! I can fetch the latest news about any company. Type one or multiple names.\"\n",
        "    elif any(t in text for t in thanks):\n",
        "        return \"😊 You're welcome! Happy to help.\"\n",
        "    elif any(gb in text for gb in goodbyes):\n",
        "        return \"👋 Goodbye! Have a great day!\"\n",
        "    return None\n",
        "\n",
        "# ---------------------------\n",
        "# Main App\n",
        "# ---------------------------\n",
        "def main():\n",
        "    st.title(\"📰 Smart Company News Chatbot\")\n",
        "\n",
        "    if 'chat_history' not in st.session_state:\n",
        "        st.session_state.chat_history = []\n",
        "\n",
        "    output_style = st.radio(\"Output style:\",\n",
        "                            ('Formal business summary', 'Quick bullet points', 'Casual conversation'))\n",
        "\n",
        "    # Display chat history\n",
        "    for msg in st.session_state.chat_history:\n",
        "        with st.chat_message(\"user\" if msg[\"role\"] == \"user\" else \"assistant\"):\n",
        "            st.markdown(msg[\"text\"])\n",
        "\n",
        "    user_input = st.chat_input(\"Type your message...\")\n",
        "    if user_input:\n",
        "        start = time.time()\n",
        "        st.session_state.chat_history.append({\"role\": \"user\", \"text\": user_input})\n",
        "\n",
        "        reply = conversation_reply(user_input)\n",
        "        if reply:\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.markdown(reply)\n",
        "            st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": reply})\n",
        "        else:\n",
        "            names = extract_names(user_input)\n",
        "            if not names:\n",
        "                combined_response = \"⚠️ Invalid input. Please enter company names.\"\n",
        "            else:\n",
        "                combined_response = \"\"\n",
        "                with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "                    results = list(executor.map(search_and_scrape, names))\n",
        "\n",
        "                for name, (data, is_valid) in zip(names, results):\n",
        "                    if not is_valid or not data:\n",
        "                        combined_response += f\"\\n⚠️ Invalid company name: '{name}'.\\n\"\n",
        "                    else:\n",
        "                        summarized = summarize(data, output_style)\n",
        "                        combined_response += f\"\\n### 📰 News for {name}:\\n\"\n",
        "                        for item in summarized:\n",
        "                            combined_response += f\"- **{item['title']}**\\n  {item['summary']}\\n  [Source]({item['source_link']})\\n\\n\"\n",
        "\n",
        "                total_time = round(time.time() - start, 2)\n",
        "                combined_response += f\"\\n⏱️ Response time: {total_time}s\"\n",
        "\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.markdown(combined_response)\n",
        "            st.session_state.chat_history.append({\"role\": \"assistant\", \"text\": combined_response})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6BFmofB4ODj",
        "outputId": "1533cf58-6f71-4df4-bd60-b2b4626cced4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Expose the port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit App URL:\", public_url)\n",
        "\n",
        "!streamlit run app.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxrbGaOS3r-a",
        "outputId": "6653c05c-1c86-4b5e-dfbb-e3329f179648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit App URL: NgrokTunnel: \"https://3e50237ffdc6.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.87.16.231:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-08-05 10:58:11.553936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754391491.592201    2293 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754391491.604014    2293 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-08-05 10:58:11.643816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ]
    }
  ]
}